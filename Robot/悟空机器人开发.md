# 悟空机器人开发

## 1、环境配置

开发文档上表明，机器人的内置开发环境为python3.8，在anaconda上配置python3.8环境并安装必须的库

```
# 创建python3.8虚拟环境
conda create --prefix=alphamini python=3.8 
# 安装AlphaMini sdk
pip install alphamini
```

查看源代码，编写requirements.txt

内容如下：

```
sentence_transformers
transformers
numpy
websocket_client
loguru
openai
```

将目录切换到requirements.txt下，运行

```
pip install -r requirements.txt
```

## 2、预处理

在encode.py中添加

```
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
```

这段代码把encode.py的所在目录的父目录即src目录加到python模块检索路径以解决识别不到config的问题

更改config.py下的

```
embdding_path = E:/Codespace/Android_new/model/embedding/bge-large-zh-v1.5'
```

访问 https://huggingface.co/BAAI/bge-large-zh-v1.5，下载所有文件(包括config.json等）到embdding_path下

运行encode.py

这段代码的主要功能是加载一个预训练的语言模型，然后使用这个模型对一个文本文件中的每一行进行编码，最后将编码结果保存到一个 pickle 文件中。让我详细解释每个部分：

### 导入部分

```python
import pickle
from loguru import logger
from sentence_transformers import SentenceTransformer
import sys
import os
```

这里导入了所需的库，包括 pickle（用于序列化对象），loguru（用于日志记录），sentence_transformers（用于文本编码），以及 sys 和 os（用于文件路径操作）。

### 添加路径

```python
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
```

这行代码将当前文件的父目录添加到 Python 的模块搜索路径中，使得可以导入同级目录下的模块。

### 导入配置：

```python
from config.config import embedding_path
from config.config import knowledge_txt_path, knowledge_pkl_path
```

从配置文件中导入必要的路径信息。

### 主函数

`load_embedding` 函数：

```python
def load_embedding() -> SentenceTransformer:
    logger.info('Loading embedding...')
    emb = SentenceTransformer(embedding_path)
    logger.info('Embedding loaded.')
    return emb
```

这个函数加载预训练的 SentenceTransformer 模型，并返回模型对象。

`encode` 函数：

```python
def encode():
    emb = load_embedding()
    with open(knowledge_txt_path, 'r', encoding='utf-8') as f:
        read_lines = f.readlines()
 
    lines = []
    for line in read_lines:
        line = line.strip()
        temp = line.split(',')[0]
        temps = ['北航', '博物馆', '航博', '校史馆']
        if not any(t in temp for t in temps):
            line = '北航' + line
        lines.append(line)
    encoded_knowledge = emb.encode([line for line in lines])
    with open(knowledge_pkl_path, 'wb') as f:
        pickle.dump(encoded_knowledge, f)
```

这个函数是主要的工作函数：

- 加载嵌入模型
- 读取文本文件
- 处理每一行文本（如果行首不包含特定词语，则在行首添加"北航"）
- 使用模型对处理后的文本进行编码
- 将编码结果保存到 pickle 文件中

```python
if __name__ == '__main__':
    encode()
    print("task done!")
```

当脚本直接运行时，执行 `encode` 函数并打印完成信息。

总的来说，这段代码的主要目的是将一个包含知识条目的文本文件转换为机器可以更容易理解和处理的向量形式，这通常用于构建知识库或问答系统的基础。处理过程中还包含了一些特定的文本预处理步骤，比如确保每个条目都包含"北航"这个关键词。

## 3、gpt调用

在gpt调用的代码中，更换api_url和api_key为镜像站的，但openai.ChatCompletion.create等语法在openai>=1.0.0版本中被更新为新的语法，在非linux终端中无法使用openai migrate迁移，访问https://github.com/openai/openai-python/discussions/742查看新的语法。

更改system_prompt

```
# 你是一名名为“悟空”的智能机器人，性格调皮可爱，你的任务是回答问题。
# 如果用户给了【已知内容】，你会根据已知内容回答问题；如果没有【已知内容】，你就根据你自己的知识回答问题。
# 初次对话时，你会介绍你是悟空。
# '''
system_prompt='''You are an intelligent robot named "悟空" with a mischievous and lovable personality. Your task is to answer questions.
If the user provides [Known Content], you will answer questions based on that content; if there is no [Known Content], you will answer questions based on your own knowledge.
In the initial conversation, you will introduce yourself as Wukong.'''

```

导入必要的库：

```python
import json
from openai import OpenAI
```

这里导入了json库用于处理JSON数据，以及OpenAI库用于与OpenAI API进行交互。

初始化OpenAI客户端：

```python
client = OpenAI(api_key="fk201080-C8ZQYpELOHvjGbkWPDyDWbwOoMfOzODP",
                base_url="https://oa.api2d.net/v1")
```

创建了一个OpenAI客户端实例，使用提供的API密钥和自定义的基础URL。

定义系统提示：

```python
system_prompt = '''...'''
```

这是给AI的系统级指令，描述了AI的角色、任务和行为方式。

初始化对话历史：

```python
history = [
    {
        "role": "system",
        "content": system_prompt
    }
]
```

创建一个列表来存储对话历史，初始只包含系统提示。

定义主要处理函数 `process_query`：

```python
def process_query(query: str, known_contents: str = "", reset: bool = False) -> str:
```

这个函数处理用户的查询，可选参数包括已知内容和是否重置对话。

函数内部逻辑：

- 如果 `reset` 为 True，重置对话历史。
- 根据是否有已知内容构造提示。
- 将用户的查询添加到对话历史中。
- 使用OpenAI API生成回复。
- 将AI的回复添加到对话历史中。
- 如果debug模式开启，打印详细的对话历史。
- 返回AI的回复内容。

API调用：

```python
completion = client.chat.completions.create(
      model="gpt-3.5-turbo",
      messages=history
)
```

使用gpt-3.5-turbo模型，基于当前的对话历史生成回复。

`json.dumps()` 函数无法直接序列化 `ChatCompletionMessage` 对象。这个对象是 OpenAI API 返回的一种特殊类型，不能直接转换为 JSON。

要解决这个问题，你需要将 `ChatCompletionMessage` 对象转换为一个普通的字典。

每次执行main函数，都会重新生成对话列表，要解决此问题，可将history列表定义在其它文件中

## 4、main函数

1. 导入相关库和模块。
2. `load_knowledge()`函数从两个文件中加载知识库数据。
   - 从`knowledge_txt_path`指定的文本文件中读取知识库的文本内容。
   - 从`knowledge_pkl_path`指定的pickle文件中读取预先计算好的知识库文本的向量表示。
   - 返回知识库文本列表和对应的向量表示列表。
3. `find_top_k()`函数用于根据给定的查询语句从知识库中检索最相关的top k个文本段。
   - 使用sentence transformer对查询语句进行编码，得到查询向量表示。
   - 计算查询向量与知识库向量的余弦相似度分数。
   - 使用`np.argpartition`函数找到分数最高的k个索引。
   - 根据索引从知识库文本列表中提取对应的文本段。
   - 返回top k个相关文本段的列表。
4. `main()`函数是程序的主入口。
   - 加载sentence transformer模型。
   - 调用`load_knowledge()`函数加载知识库数据。
   - 定义一个查询语句`query`。
   - 调用`find_top_k()`函数检索与查询相关的top k个文本段。
   - 使用OpenAI的ChatGPT模型处理查询和相关文本段，并打印响应结果。
5. 最后，如果直接运行该脚本，则执行`main()`函数。

总的来说，这个程序利用sentence transformer进行语义搜索，从知识库中检索与查询相关的文本段，然后使用ChatGPT模型结合这些文本段生成响应。它可以用于问答系统或信息检索任务。

## 5、更改知识库

在knowledge.txt中加入关于北航杭州校区和中法航空学院的语料

